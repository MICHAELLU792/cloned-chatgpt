import streamlit as st
from utils import get_chat_response
from langchain.memory import ConversationBufferMemory

st.title("ğŸ’¬ AI èŠå¤©åŠ©æ‰‹")

with st.sidebar:
    openai_api_key = st.text_input("è«‹è¼¸å…¥OpenAI APIå¯†é‘°: ", type="password")
    st.markdown("[ç²å–OpenAI APIå¯†é‘°](https://platform.openai.com/api-keys)")

if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
    st.session_state["messages"] = [{"role": "ai",
                                     "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€éº¼å¯ä»¥å¹«ä½ çš„å—ï¼Ÿ"}]

# æ¯ä¸€æ¢å°è©±çš„æ‰“å°
for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

prompt = st.chat_input()
if prompt:
    if not openai_api_key:
        st.info("è«‹è¼¸å…¥ä½ çš„OpenAI APIå¯†é‘°")
        st.stop()
    # å­˜å…¥ç”¨æˆ¶è¼¸å…¥çš„å°è©±
    st.session_state["messages"].append({"role": "human", "content": prompt})
    # æ‰“å°ç”¨æˆ¶è¼¸å…¥çš„å°è©±
    st.chat_message("human").write(prompt)

    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè«‹ç¨ç­‰..."):
        response = get_chat_response(prompt, st.session_state["memory"],
                                     openai_api_key)
    msg = {"role": "ai", "content": response}
    # å­˜å…¥AIå‚³å›çš„å°è©±
    st.session_state["messages"].append(msg)
    # æ‰“å°AIå‚³å›çš„å°è©±
    st.chat_message("ai").write(response)